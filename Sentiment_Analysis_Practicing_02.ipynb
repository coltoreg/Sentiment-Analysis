{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis Practicing-Lesson 02",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S4r5PZHosup",
        "colab_type": "text"
      },
      "source": [
        "# **Lesson02: Probabilistic-Based Methods**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRTagJGYfegu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "f2255b73-0af0-4664-b499-6c16ef27fe97"
      },
      "source": [
        "!gdown --id 1p4moPeR2QoRmoTPWTx0rbtGdGocZPhWA"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1p4moPeR2QoRmoTPWTx0rbtGdGocZPhWA\n",
            "To: /content/ChnSentiCorp_htl_ba_6000_cutted.csv\n",
            "\r  0% 0.00/1.74M [00:00<?, ?B/s]\r100% 1.74M/1.74M [00:00<00:00, 114MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f737XpiZuYWG",
        "colab_type": "text"
      },
      "source": [
        "## **Load Dataset and do some process**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc-jFIzrqMPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "outputId": "99b168eb-08be-4931-9467-d53eb6e17861"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "seed = 42\n",
        "\n",
        "data = pd.read_csv('ChnSentiCorp_htl_ba_6000_cutted.csv', compression='gzip')\n",
        "\n",
        "if isinstance(data.cut[0], str):\n",
        "    data.cut = data.cut.apply(lambda x: eval(x))\n",
        "data.sample(20, random_state=seed)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>review</th>\n",
              "      <th>cut</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1782</th>\n",
              "      <td>1</td>\n",
              "      <td>没有想象的离西湖近 年轻人走走也得10 15分钟 因为窗不是面对西湖的 所以景基本看不到西湖...</td>\n",
              "      <td>[没有, 想象, 西湖, 近, 年轻人, 走走, 10, 15, 分钟, 窗, 面对, 西湖...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3917</th>\n",
              "      <td>0</td>\n",
              "      <td>住的标准单人间实在是小 房间里一张大床已经塞得满满的了 设施极其简陋除了电视机和烧水壶其他什...</td>\n",
              "      <td>[住, 标准, 单人间, 实在, 小, 房间, 里, 一张, 大床, 塞得, 满满的, 设施...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>1</td>\n",
              "      <td>初到当地 在携程上订了一晚这家酒店 印象中原来认为新疆很偏僻 没想到酒店的环境及服务与内地的...</td>\n",
              "      <td>[初到, 携程, 上订, 一晚, 这家, 酒店, 印象, 中, 新疆, 偏僻, 没想到, 酒...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2135</th>\n",
              "      <td>1</td>\n",
              "      <td>酒店的床比一般的香港酒店大 双人房的床都很大 枕头超多超舒服 酒店正好在金钟的正上方 逛街很...</td>\n",
              "      <td>[酒店, 床, 比, 一般, 香港, 酒店, 大, 双人房, 床, 很大, 枕头, 超多超,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5224</th>\n",
              "      <td>0</td>\n",
              "      <td>在网上综合考虑后 并打电话给汉庭 汉庭说靠街边的窗户都换成双层窗户 隔音很好 也有停车场 汉...</td>\n",
              "      <td>[网上, 综合, 后, 打电话, 给汉庭, 汉庭, 说, 靠, 街边, 窗户, 换成, 双层...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1168</th>\n",
              "      <td>1</td>\n",
              "      <td>总体感觉很不错 酒店硬件和软件都还满意 前台服务生服务热情到位 房间安静 不嘈杂 总体房间还...</td>\n",
              "      <td>[总体, 感觉, 不错, 酒店, 硬件, 和, 软件, 满意, 前台, 服务生, 服务, 热...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>1</td>\n",
              "      <td>感觉还算可以的 不过没有香格里拉那么好 价格和协议的也没什么区别 所以还是去香格里拉较划算点</td>\n",
              "      <td>[感觉, 算, 没有, 香格里拉, 好, 价格, 和, 协议, 没什么, 区别, 香格里拉,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>1</td>\n",
              "      <td>各方面都一般 只要期望值不太高就还可以</td>\n",
              "      <td>[方面, 一般, 期望值, 不太高]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1657</th>\n",
              "      <td>1</td>\n",
              "      <td>这次来的比较晚 出去吃饭不太方便 就在酒店的餐厅吃的海鲜自助 还可以 不过感觉价格稍微偏高了...</td>\n",
              "      <td>[来, 比较, 晚, 吃饭, 不太, 方便, 酒店, 餐厅, 吃, 海鲜, 自助, 感觉, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>1</td>\n",
              "      <td>我订的是行政房 但酒店给我免费升级到公寓房 是他们新的房子 房间设施 装修都非常不错 而且可...</td>\n",
              "      <td>[我订, 行政, 房, 酒店, 给, 免费, 升级, 公寓, 房, 新, 房子, 房间, 设...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5302</th>\n",
              "      <td>0</td>\n",
              "      <td>差得要命 很大股霉味 勉强住了一晚 第二天大早赶紧溜</td>\n",
              "      <td>[差得, 要命, 很大, 股, 霉味, 勉强, 住, 一晚, 第二天, 大, 早, 赶紧, 溜]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2611</th>\n",
              "      <td>1</td>\n",
              "      <td>订家庭间入住的是虹口商务酒店 因为到达之后临时改订单 与前台小姐发生了点不愉快 但之后的客房...</td>\n",
              "      <td>[订, 家庭, 间, 入住, 虹口, 商务酒店, 到达, 临时, 改, 订单, 与, 前台,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>811</th>\n",
              "      <td>1</td>\n",
              "      <td>房间环境还行 还有液晶电脑 晚上还有水果 就是周围购物要走点路 整体还行</td>\n",
              "      <td>[房间, 环境, 行, 液晶电脑, 晚上, 水果, 周围, 购物, 走, 点路, 整体, 行]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>1</td>\n",
              "      <td>跟众人评价的差不多 商务大床的房间比浦东店的要小很多 总体来说这个价位来讲设施还是蛮好的 宾...</td>\n",
              "      <td>[众人, 评价, 商务, 大床, 房间, 比, 浦东店, 小, 总体, 价位, 设施, 蛮,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3593</th>\n",
              "      <td>0</td>\n",
              "      <td>175元入住标房B 大厅和电梯里有异味 房间里桌子也没擦干净 洗浴间装潢等设备太旧 早饭很差...</td>\n",
              "      <td>[175, 元, 入住, 标房, B, 大厅, 和, 电梯, 里, 异味, 房间, 里, 桌...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2638</th>\n",
              "      <td>1</td>\n",
              "      <td>本人25号入住该酒店 27号离开 给我的感觉是酒店卫生不错 房间也很安静 交通比较方便 楼下...</td>\n",
              "      <td>[25, 号, 入住, 酒店, 27, 号, 离开, 给, 感觉, 酒店, 卫生, 不错, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2187</th>\n",
              "      <td>1</td>\n",
              "      <td>看了网上的评价因此预期并不高订的是三人间进到房间里感到还可以尽管住的是传说中条件不好的前楼人...</td>\n",
              "      <td>[看, 网上, 评价, 因此, 预期, 高订, 三人间, 进, 房间, 里, 感到, 尽管,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5351</th>\n",
              "      <td>0</td>\n",
              "      <td>楼很老 房间很大 服务不错 二楼的早茶不错</td>\n",
              "      <td>[楼, 老, 房间, 很大, 服务, 不错, 二楼, 早茶, 不错]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>1</td>\n",
              "      <td>晚上询问需不需要保健按摩的电话不停 如隔天一早赶飞机的人 最好拔掉电话线自保</td>\n",
              "      <td>[晚上, 询问, 需不需要, 保健, 按摩, 电话, 不停, 隔天, 一早, 赶, 飞机, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>1</td>\n",
              "      <td>酒店环境比我想象的好 房间也非常干净 我住的是400一晚的 早餐时间比较短 睡过头了就没有去...</td>\n",
              "      <td>[酒店, 环境, 比, 想象, 好, 房间, 非常, 干净, 住, 400, 一晚, 早餐时...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label  ...                                                cut\n",
              "1782      1  ...  [没有, 想象, 西湖, 近, 年轻人, 走走, 10, 15, 分钟, 窗, 面对, 西湖...\n",
              "3917      0  ...  [住, 标准, 单人间, 实在, 小, 房间, 里, 一张, 大床, 塞得, 满满的, 设施...\n",
              "221       1  ...  [初到, 携程, 上订, 一晚, 这家, 酒店, 印象, 中, 新疆, 偏僻, 没想到, 酒...\n",
              "2135      1  ...  [酒店, 床, 比, 一般, 香港, 酒店, 大, 双人房, 床, 很大, 枕头, 超多超,...\n",
              "5224      0  ...  [网上, 综合, 后, 打电话, 给汉庭, 汉庭, 说, 靠, 街边, 窗户, 换成, 双层...\n",
              "1168      1  ...  [总体, 感觉, 不错, 酒店, 硬件, 和, 软件, 满意, 前台, 服务生, 服务, 热...\n",
              "879       1  ...  [感觉, 算, 没有, 香格里拉, 好, 价格, 和, 协议, 没什么, 区别, 香格里拉,...\n",
              "156       1  ...                                 [方面, 一般, 期望值, 不太高]\n",
              "1657      1  ...  [来, 比较, 晚, 吃饭, 不太, 方便, 酒店, 餐厅, 吃, 海鲜, 自助, 感觉, ...\n",
              "323       1  ...  [我订, 行政, 房, 酒店, 给, 免费, 升级, 公寓, 房, 新, 房子, 房间, 设...\n",
              "5302      0  ...   [差得, 要命, 很大, 股, 霉味, 勉强, 住, 一晚, 第二天, 大, 早, 赶紧, 溜]\n",
              "2611      1  ...  [订, 家庭, 间, 入住, 虹口, 商务酒店, 到达, 临时, 改, 订单, 与, 前台,...\n",
              "811       1  ...    [房间, 环境, 行, 液晶电脑, 晚上, 水果, 周围, 购物, 走, 点路, 整体, 行]\n",
              "393       1  ...  [众人, 评价, 商务, 大床, 房间, 比, 浦东店, 小, 总体, 价位, 设施, 蛮,...\n",
              "3593      0  ...  [175, 元, 入住, 标房, B, 大厅, 和, 电梯, 里, 异味, 房间, 里, 桌...\n",
              "2638      1  ...  [25, 号, 入住, 酒店, 27, 号, 离开, 给, 感觉, 酒店, 卫生, 不错, ...\n",
              "2187      1  ...  [看, 网上, 评价, 因此, 预期, 高订, 三人间, 进, 房间, 里, 感到, 尽管,...\n",
              "5351      0  ...                 [楼, 老, 房间, 很大, 服务, 不错, 二楼, 早茶, 不错]\n",
              "319       1  ...  [晚上, 询问, 需不需要, 保健, 按摩, 电话, 不停, 隔天, 一早, 赶, 飞机, ...\n",
              "167       1  ...  [酒店, 环境, 比, 想象, 好, 房间, 非常, 干净, 住, 400, 一晚, 早餐时...\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmx8l77luWyW",
        "colab_type": "text"
      },
      "source": [
        "### Label transform from string to one-hot vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN99J938uOpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "y = le.fit_transform(data.label)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPntdP5Yuqkr",
        "colab_type": "text"
      },
      "source": [
        "### Split Train and Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4DVJQLvuV9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  data.cut.str.join(sep=' ').values, y, \n",
        "  test_size=0.2, random_state=seed, shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOyvvzZOu04K",
        "colab_type": "text"
      },
      "source": [
        "## **Define Metric object**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y5lM_kout80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "\n",
        "class Metric(object):\n",
        "\n",
        "  def __init__(self, y_true):\n",
        "    self.y_true = y_true\n",
        "      \n",
        "  def get_metric(self, y_pred, y_true=None):\n",
        "    if y_true is None:\n",
        "      y_true = self.y_true\n",
        "    \n",
        "    loss = np.nan\n",
        "    if y_pred.ndim > 1:\n",
        "      loss = log_loss(y_true=y_true, y_pred=y_pred)\n",
        "      y_pred = y_pred.argmax(axis=1)\n",
        "    \n",
        "    acuuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
        "    precision, recall, f_score, _ = precision_recall_fscore_support(\n",
        "      y_true=y_true, y_pred=y_pred, average='macro', zero_division='warn')\n",
        "    \n",
        "    print('loss:', loss)\n",
        "    print('acuuracy:', acuuracy)\n",
        "    print('precision:', precision)\n",
        "    print('recall:', recall)\n",
        "    print('f_score:', f_score)\n",
        "\n",
        "\n",
        "metric_fn = Metric(y_true=y_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skm3DNZnu8PN",
        "colab_type": "text"
      },
      "source": [
        "## **Create feature Vecotr**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15xaldpevBAW",
        "colab_type": "text"
      },
      "source": [
        "### Create Bag-of-Words feature vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RRxwXVKu5S-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "count_vectorizer = CountVectorizer(ngram_range=(1, 2), min_df=5, max_df=0.5)\n",
        "\n",
        "count_vectorizer.fit(data.cut.str.join(sep=' ').values)\n",
        "\n",
        "X_train_count = count_vectorizer.transform(X_train)\n",
        "X_test_count = count_vectorizer.transform(X_test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiP0npzGvLt7",
        "colab_type": "text"
      },
      "source": [
        "### Create TF-IDF feature vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdxo2t3evI9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "\n",
        "tfidf_transformer = TfidfTransformer(smooth_idf=True, sublinear_tf=True)\n",
        "\n",
        "tfidf_transformer.fit(count_vectorizer.transform(data.cut.str.join(sep=' ').values))\n",
        "\n",
        "X_train_tfidf = tfidf_transformer.transform(X_train_count)\n",
        "X_test_tfidf = tfidf_transformer.transform(X_test_count)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayDzAWB9vRnb",
        "colab_type": "text"
      },
      "source": [
        "## Train a Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gmVgOPpvXka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRh6nAJvvZI2",
        "colab_type": "text"
      },
      "source": [
        "### Using Bag-of-Words feature to train a logistic regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5tY-RtbvLJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "1ab8b460-fe45-42e7-c1eb-2263fe6e54e7"
      },
      "source": [
        "clf_count = LogisticRegression(random_state=seed, n_jobs=-1)\n",
        "\n",
        "clf_count.fit(X_train_count, y_train)\n",
        "        \n",
        "metric_fn.get_metric(clf_count.predict_proba(X_test_count))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.2629031947573188\n",
            "acuuracy: 0.9058333333333334\n",
            "precision: 0.9069177350427351\n",
            "recall: 0.906457475870617\n",
            "f_score: 0.9058254200526572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFrbL9aDvutw",
        "colab_type": "text"
      },
      "source": [
        "Using TF-IDF feature to train a logistic regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwH6gchevVqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "02fc9801-a03f-4eaa-dbf6-b331e2d0ac4e"
      },
      "source": [
        "clf_tfidf = LogisticRegression(random_state=42, n_jobs=-1)\n",
        "\n",
        "clf_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "metric_fn.get_metric(clf_tfidf.predict_proba(X_test_tfidf))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.3491885562397428\n",
            "acuuracy: 0.8875\n",
            "precision: 0.8906265717383286\n",
            "recall: 0.8885129407972076\n",
            "f_score: 0.8874148574859738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXCNiv2QwGqc",
        "colab_type": "text"
      },
      "source": [
        "## Train a Naive Bayes Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21RgfczfwbBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqaBbIpkwQgL",
        "colab_type": "text"
      },
      "source": [
        "### Using Bag-of-Words feature to train a Multinomial Naive Bayes model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNULMl78wXuV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "ff91d2f5-6528-4ee7-88d7-3e706743a0bb"
      },
      "source": [
        "clf_mnb_count = MultinomialNB()\n",
        "\n",
        "clf_mnb_count.fit(X_train_count, y_train)\n",
        "\n",
        "metric_fn.get_metric(clf_mnb_count.predict_proba(X_test_count))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.6085395752478586\n",
            "acuuracy: 0.8866666666666667\n",
            "precision: 0.8876001104667219\n",
            "recall: 0.8861437730490147\n",
            "f_score: 0.8864534514811144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOlBRNJOwz1c",
        "colab_type": "text"
      },
      "source": [
        "### Using TF-IDF feature to train a Multinomial Naive Bayes model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mzsbl1KwZwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "80220783-de3a-4f09-9fa6-adc89d5f5f3d"
      },
      "source": [
        "clf_mnb_tfidf = MultinomialNB()\n",
        "\n",
        "clf_mnb_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "metric_fn.get_metric(clf_mnb_tfidf.predict_proba(X_test_tfidf))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.31485330766091335\n",
            "acuuracy: 0.89\n",
            "precision: 0.8900987042460348\n",
            "recall: 0.8898038245732025\n",
            "f_score: 0.8899116234977524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BH7ib0ww9Qb",
        "colab_type": "text"
      },
      "source": [
        "## **Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaTXc9e7whuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.utils.fixes import loguniform\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [1, 10, 100],\n",
        "    'max_iter': [100, 200, 300]\n",
        "}\n",
        "grid = GridSearchCV(estimator=clf_tfidf, param_grid=param_grid, n_jobs=-1, cv=5)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxCcNZPbxAVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "b31c79ce-6be1-4c1a-e774-f8ee62584e2a"
      },
      "source": [
        "grid.fit(X_train_tfidf, y_train)\n",
        "\n",
        "metric_fn.get_metric(grid.predict_proba(X_test_tfidf))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.24736313915278496\n",
            "acuuracy: 0.8966666666666666\n",
            "precision: 0.8990568485183232\n",
            "recall: 0.8975574644763792\n",
            "f_score: 0.8966181346243097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWjfDMx6xBnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}